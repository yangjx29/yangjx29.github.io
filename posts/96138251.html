<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="ML-based-knowledge, JacksonYang的博客">
    <meta name="description" content="

ML知识点汇总1.LSTM
原理分析

2.预训练思想有了图像领域预训练的引入，我们在此给出预训练的思想：任务 A 对应的模型 A 的参数不再是随机初始化的，而是通过任务 B 进行预先训练得到模型 B，然后利用模型 B 的参数对模型 A">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>ML-based-knowledge | JacksonYang的博客</title>
    <link rel="icon" type="image/png" href="/medias/image.png">
    
    <style>
        body{
            background-image: url(/medias/banner/11.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/image.svg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JacksonYang的博客</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/image.svg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JacksonYang的博客</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/22.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">ML-based-knowledge</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/ML/" class="post-category">
                                ML
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-09-25
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    20 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <meta name="referrer" content="no-referrer"/>

<h1 id="ML知识点汇总"><a href="#ML知识点汇总" class="headerlink" title="ML知识点汇总"></a>ML知识点汇总</h1><h2 id="1-LSTM"><a href="#1-LSTM" class="headerlink" title="1.LSTM"></a>1.LSTM</h2><ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38147421/article/details/107692418">原理分析</a></li>
</ol>
<h2 id="2-预训练思想"><a href="#2-预训练思想" class="headerlink" title="2.预训练思想"></a>2.预训练思想</h2><p>有了图像领域预训练的引入，我们在此给出预训练的思想：任务 A 对应的模型 A 的参数不再是随机初始化的，而是通过任务 B 进行预先训练得到模型 B，然后利用模型 B 的参数对模型 A 进行初始化，再通过任务 A 的数据对模型 A 进行训练。注：模型 B 的参数是随机初始化的。</p>
<h2 id="3-神经网络语言模型NNLM"><a href="#3-神经网络语言模型NNLM" class="headerlink" title="3.神经网络语言模型NNLM"></a>3.神经网络语言模型NNLM</h2><p>神经网络语言模型则引入神经网络架构来估计单词的分布，<strong>并且通过词向量的距离衡量单词之间的相似度，因此，对于未登录单词，也可以通过相似词进行估计，进而避免出现数据稀疏问题</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/direct/4063e81a2a4f47569b2231ca4e19822a.png" alt="image-20240925143535796"></p>
<p>上图所示有一个 $V×m $ 的矩阵 $Q$，这个矩阵$Q$包含 $V$ 行，$V$ 代表词典大小，每一行的内容代表对应单词的 Word Embedding 值。</p>
<p>只不过  $Q$ 的内容也是网络参数，需要学习获得，训练刚开始用随机值初始化矩阵  $Q$，当这个网络训练好之后，矩阵  $Q$ 的内容被正确赋值，每一行代表一个单词对应的 Word embedding 值</p>
<p>上图为神经网络语言模型结构图，它的学习任务是输入某个句中单词 $w_t$&#x3D;bert 前的 t−1 个单词，要求网络正确预测单词 “bert”，即最大化：</p>
<p>$P(w_t&#x3D;bert|w1,w2,⋯,wt−1;θ)$</p>
<p>上图所示的神经网络语言模型分为三层，接下来我们详细讲解这三层的作用：</p>
<ol>
<li>神经网络语言模型的第一层，为输入层。首先将前 n−1 个单词用 Onehot 编码（例如：0001000）作为原始单词输入，之后乘以一个随机初始化的矩阵 Q 后获得词向量 $C(w_i)$，对这 n−1个词向量处理后得到输入 x，记作 $x&#x3D;(C(w_1),C(w_2),⋯,C(w_{t−1}))$</li>
<li>神经网络语言模型的第二层，为隐层，包含 h 个隐变量，H 代表权重矩阵，因此隐层的输出为 $H_x+ d$，其中 d 为偏置项。并且在此之后使用 tanh 作为激活函数。</li>
<li>神经网络语言模型的第三层，为输出层，一共有 $|V|$ 个输出节点（字典大小），直观上讲，每个输出节点$yi$是词典中每一个单词概率值。最终得到的计算公式为：$y&#x3D;softmax(b+W_x+Utanh⁡(d+H_x))$，其中 W 是直接从输入层到输出层的权重矩阵，U 是隐层到输出层的参数矩阵。</li>
</ol>
<ul>
<li>Word Embedding 其实就是<strong>标准的预训练过程</strong></li>
</ul>
<h2 id="4-词向量"><a href="#4-词向量" class="headerlink" title="4.词向量"></a>4.词向量</h2><h3 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h3><p><strong>把单词用向量表示，是把深度神经网络语言模型引入自然语言处理领域的一个核心技术。</strong></p>
<p>在自然语言处理任务中，训练集大多为一个字或者一个词，把他们转化为计算机适合处理的数值类数据非常重要。</p>
<p>早期，人们想到的方法是使用独热（Onehot）编码，如下图所示<img src="https://img-blog.csdnimg.cn/direct/5b002586caa9442ca55946e3e5433dab.png" alt="image-20240925145525155"></p>
<p>但是，对于独热表示的向量，如果采用余弦相似度计算向量间的相似度，<strong>可以明显的发现任意两者向量的相似度结果都为 0</strong>，即任意二者都不相关，也就是说独热表示无法解决词之间的相似性问题</p>
<h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><p>在神经网络语言模型中出现的一个词向量 C(wi)，对的，<strong>这个 C(wi) 其实就是单词对应的 Word Embedding 值，也就是我们这节的核心——词向量。</strong></p>
<p><img src="https://img-blog.csdnimg.cn/direct/4063e81a2a4f47569b2231ca4e19822a.png" alt="image-20240925143535796"></p>
<p>上图所示有一个 $V×m $ 的矩阵 $Q$，这个矩阵$Q$包含 $V$ 行，$V$ 代表词典大小，每一行的内容代表对应单词的 Word Embedding 值。</p>
<p>只不过  $Q$ 的内容也是网络参数，需要学习获得，训练刚开始用随机值初始化矩阵  $Q$，当这个网络训练好之后，矩阵  $Q$ 的内容被正确赋值，每一行代表一个单词对应的 Word embedding 值</p>
<p>但是这个词向量有没有解决词之间的相似度问题呢？为了回答这个问题，我们可以看看词向量的计算过程：</p>
<p>$[0&amp;0&amp;0&amp;1&amp;0] \begin{matrix}7&amp;24&amp;1\23&amp;5&amp;7\4&amp;6&amp;13\10&amp;12&amp;19&amp;\11&amp;18&amp;25 \end{matrix} &#x3D; [10&amp;12&amp;19]$</p>
<p>通过上述词向量的计算，可以发现第 4 个词的词向量表示为 [10 12 19]。</p>
<p>如果再次采用<strong>余弦相似度计算两个词之间的相似度，结果不再是 0</strong> ，既可以一定程度上描述两个词之间的相似度</p>
<h3 id="Word2Vec模型"><a href="#Word2Vec模型" class="headerlink" title="Word2Vec模型"></a>Word2Vec模型</h3><ul>
<li>Word2Vec工作原理</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/direct/e3ce8be556be47b596df3d82c1f4a734.png" alt="image-20240925151659106"></p>
<p>Word2Vec 的网络结构其实和神经网络语言模型（NNLM）是基本类似的，不过这里需要指出：尽管网络结构相近，而且都是做语言模型任务，但是<strong>他们训练方法不太一样</strong>。</p>
<p>Word2Vec 有两种训练方法：</p>
<ol>
<li>第一种叫 <strong>CBOW</strong>，<strong>核心思想是从一个句子里面把一个词抠掉</strong>，用这个词的上文和下文去预测被抠掉的这个词；</li>
<li>第二种叫做 <strong>Skip-gram</strong>，和 CBOW 正好反过来，输入某个单词，要求网络预测它的上下文单词。</li>
</ol>
<p>而NNLM的训练方法是<strong>输入一个单词的上文，去预测这个单词</strong></p>
<p>为什么 Word2Vec 这么处理？原因很简单，因为 Word2Vec 和 NNLM 不一样，NNLM 的主要任务是要学习一个解决语言模型任务的网络结构，语言模型就是要看到上文预测下文，而 Word Embedding只是 NNLM 无心插柳的一个副产品；但是 Word2Vec 目标不一样，它单纯就是要 Word Embedding 的，这是主产品，所以它完全可以随性地这么去训练网络。</p>
<h3 id="EMLO"><a href="#EMLO" class="headerlink" title="EMLO"></a>EMLO</h3><p>word embedding无法区分多义词。</p>
<p>ELMo 的本质思想是：先用语言模型学好一个单词的 Word Embedding，此时多义词无法区分，不过这没关系。在实际使用 Word Embedding 的时候，单词已经具备了特定的上下文了，这个时候我可以根据上下文单词的语义再去调整单词的 Word Embedding 表示，这样经过调整后的 Word Embedding 更能表达在这个上下文中的具体含义，自然也就解决了多义词的问题了。所以 ELMo 本身是个<strong>根据当前上下文对 Word Embedding 动态调整的思路。</strong></p>
<p>ELMo 采用了典型的两阶段过程：</p>
<ol>
<li>第一个阶段是利用语言模型进行<strong>预训练</strong>；</li>
<li>第二个阶段是在做<strong>下游任务</strong>时<strong>，从预训练网络中提取对应单词的网络各层的 Word Embedding 作为新特征补充到下游任务中。</strong></li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/direct/5aa3f88d24e546edac02bcabf59f17e7.png" alt="image-20240925164420747"></p>
<p>上图展示的是其<strong>第一阶段预训练过程</strong>，它的网络结构采用了双层双向 LSTM，目前语言模型训练的任务目标是根据单词 $w_i$ 的上下文去正确预测单词 $w_i$ ，$w_i$ 之前的单词序列 Context-before 称为上文，之后的单词序列 Context-after 称为下文。</p>
<p>图中左端的前向双层 LSTM 代表正方向编码器，输入的是从左到右顺序的除了预测单词外$w_i$的上文 Context-before；右端的逆向双层 LSTM 代表反方向编码器，输入的是从右到左的逆序的句子下文Context-after；每个编码器的深度都是两层 LSTM 叠加。</p>
<p>使用这个网络结构利用大量语料做语言模型任务就能预先训练好这个网络，如果训练好这个网络后，输入一个新句子 $s_{new}$ ，句子中每个单词都能得到对应的三个 Embedding：</p>
<ul>
<li>最底层是单词的 Word Embedding；</li>
<li>往上走是第一层双向 LSTM 中对应单词位置的 Embedding，这层编码单词的<strong>句法信息</strong>更多一些；</li>
<li>再往上走是第二层 LSTM 中对应单词位置的 Embedding，这层编码单词的<strong>语义信息</strong>更多一些</li>
</ul>
<p>也就是说，ELMo 的预训练过程不仅仅学会单词的 Word Embedding，还学会了一个双层双向的 LSTM 网络结构，而这两者后面都有用。</p>
<h4 id="ELMo-的-Feature-based-Pre-Training"><a href="#ELMo-的-Feature-based-Pre-Training" class="headerlink" title="ELMo 的 Feature-based Pre-Training"></a>ELMo 的 Feature-based Pre-Training</h4><p>预训练好之后，elmo如何给下游任务使用呢？</p>
<p><img src="https://img-blog.csdnimg.cn/direct/be676db332e64faba09f2333dd5e1b42.png" alt="image-20240925165426685"></p>
<p>上图展示了下游任务的使用过程，比如我们的下游任务仍然是 QA 问题，此时对于问句 X：</p>
<ol>
<li>我们可以先将句子 X 作为预训练好的 ELMo 网络的输入，这样句子 X 中每个单词在 ELMO 网络中都能获得对应的三个 Embedding；</li>
<li>之后给予这三个 Embedding 中的每一个 Embedding 一个权重 a，这个权重可以学习得来，根据各自权重累加求和，将三个 Embedding 整合成一个；</li>
<li>然后将整合后的这个 Embedding 作为 X 句在自己任务的那个网络结构中对应单词的输入，以此作为补充的新特征给下游任务使用。</li>
<li>对于上图所示下游任务 QA 中的回答句子 Y 来说也是如此处理。</li>
</ol>
<p><strong>因为 ELMo 给下游提供的是每个单词的特征形式，所以这一类预训练的方法被称为 “Feature-based Pre-Training”。</strong></p>
<p>至于为何这么做能够达到区分多义词的效果，原因在于在训练好 ELMo 后，<strong>在特征提取的时候，每个单词在两层 LSTM 上都会有对应的节点，这两个节点会编码单词的一些句法特征和语义特征，并且它们的 Embedding 编码是动态改变的</strong>，会受到上下文单词的影响，周围单词的上下文不同应该会强化某种语义，弱化其它语义，进而就解决了多义词的问题。</p>
<h2 id="5-RNN和LSTM"><a href="#5-RNN和LSTM" class="headerlink" title="5.RNN和LSTM"></a>5.RNN和LSTM</h2><p>RNN（Recurrent Neural Network） 和 LSTM（Long Short-Term Memory）</p>
<h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><ul>
<li>传统的神经网络无法获取时序信息，然而<strong>时序信息在自然语言处理任务中非常重要</strong></li>
<li>RNN 的基本单元结构如下图所示<img src="https://img-blog.csdnimg.cn/direct/c2ce040182ce479d9047347cc4fc23f4.png" alt="image-20240925152242019"></li>
</ul>
<p>上图左边部分称作 RNN 的一个 timestep，在这个 timestep 中可以看到，在 $t$ 时刻，输入变量 $x_t$，通过 RNN 的一个基础模块 A，输出变量 $h_t$，而 $t$ 时刻的信息，将会传递到下一个时刻 $t+1$</p>
<p>如果把模块按照时序展开，则会如上图右边部分所示，<strong>由此可以看到 RNN 为多个基础模块 A 的互连，每一个模块都会把当前信息传递给下一个模块</strong>。</p>
<p>RNN 解决了时序依赖问题，但这里的时序一般指的是<strong>短距离</strong>的，首先我们先介绍下短距离依赖和长距离依赖的区别：</p>
<ul>
<li>短距离依赖：对于这个填空题 “我想看一场篮球____”，我们很容易就判断出 “篮球” 后面跟的是 “比赛”，这种短距离依赖问题非常适合 RNN。</li>
<li>长距离依赖：对于这个填空题 “我出生在中国的瓷都景德镇，小学和中学离家都很近，……，我的母语是____”，对于短距离依赖，“我的母语是” 后面可以紧跟着 “汉语”、“英语”、“法语”，但是如果我们想精确答案，则必须回到上文中很长距离之前的表述 “我出生在中国的瓷都景德镇”，进而判断答案为 “汉语”，而 RNN 是很难学习到这些信息的。</li>
</ul>
<h4 id="RNN梯度消失问题"><a href="#RNN梯度消失问题" class="headerlink" title="RNN梯度消失问题"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhaojc1995/article/details/114649486">RNN梯度消失问题</a></h4><ul>
<li>为什么<strong>RNN不适合长距离依赖问题</strong></li>
</ul>
<img src="https://img-blog.csdnimg.cn/direct/14b5df8af70c486d8d0851038a4fee26.png" alt="image-20240925153100124" style="zoom:70%;" />

<p>如上图所示，为RNN模型结构，前向传播过程包括：</p>
<ul>
<li><p>隐藏状态: $h^{t}&#x3D;\sigma({z^{(t)}}) &#x3D; \sigma(Ux^{t}+Wh^{(t-1)}+b)$,此处激活函数一般为 tanh</p>
</li>
<li><p>模型输出：$o^{(t)}&#x3D;Vh^{(t)}+c$</p>
</li>
<li><p>预测输出：$\hat{y}^2&#x3D;\sigma(o^{(t)})$,此处激活函数一般为softmax。</p>
</li>
<li><p>模型损失：$L &#x3D;\sum_{t&#x3D;1}^NL^{(t)}$</p>
<p>RNN 所有的 timestep 共享一套参数 U,V,W，在 RNN 反向传播过程中，需要计算 U,V,W等参数的梯度，以 W 的梯度表达式为例（假设 RNN 模型的损失函数为 L）：</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/direct/6774cdb7aea643be947368f7f3f9d350.png" alt="image-20240925154324891"></p>
<p>需要注意的是，RNN和DNN梯度消失和梯度爆炸含义并不相同</p>
<p>RNN中权重在各时间步内共享，最终的梯度是各个时间步的梯度和，梯度和会越来越大。因此，RNN中总的梯度是不会消失的，即使梯度越传越弱，也只是远距离的梯度消失。 从公式（9）中的$(\prod_{k&#x3D;t+1}^Ttanh^\prime{(z^{(k)}W)}$可以看到，<strong>RNN所谓梯度消失的真正含义是，梯度被近距离（$t+1趋向于T$）梯度主导，远距离（$t+1远离T$）梯度很小，导致模型难以学到远距离的信息。</strong></p>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>为了解决 RNN 缺乏的序列长距离依赖问题，LSTM 被提了出来</p>
<p><img src="https://img-blog.csdnimg.cn/direct/ee36d17132d54828b2bdd229f3f1fda1.png" alt="image-20240925155356045"></p>
<p>如上图所示，为 LSTM 的 RNN 门控结构（LSTM 的 timestep），LSTM 前向传播过程包括</p>
<ul>
<li><p>遗忘门：</p>
<p><strong>决定了丢弃哪些信息，</strong>遗忘门接收$t−1$时刻的状态$h_{t−1}$，以及当前的输入$x_t$，经过 Sigmoid 函数后输出一个 0 到 1 之间的值$f_t$</p>
<ul>
<li>输出：$i_t&#x3D;σ(W^ih_{t−1}+U_ix_t+b_i), \widehat{C}<em>t&#x3D;tanhW_ah</em>{t−1}+U_ax_t+b_a$</li>
</ul>
</li>
<li><p>输入门：<strong>决定了哪些新信息被保留</strong>，并更新cell状态，输入门的取值由 $h_{t−1}$ 和 ${x_t}$决定，通过 Sigmoid 函数得到一个 0 到 1 之间的值 $i_t$，而 $tanh$ 函数则创造了一个当前cell状态的候选 $a_t$</p>
<ul>
<li>输出：$i_t&#x3D;\sigma(W_ih_{t-1}+U_ix_t+b_i) , \tilde{C}<em>t&#x3D;tanhW_ah</em>{t-1}+U_ax_t+b_a$</li>
</ul>
</li>
<li><p>cell状态：旧cell状态 $C_{t−1}$ 被更新到新的cell状态 $C_t$ 上</p>
<ul>
<li>输出：$C_t&#x3D;C_{t-1}\odot f_t+i_t\odot\tilde{C_t}$</li>
</ul>
</li>
<li><p>输出门：决定了最后输出的信息，输出门取值由$h_{t−1}$ 和$x_{t}$决定，通过 Sigmoid 函数得到一个 0 到 1 之间的值 $o_t$，最后通过 $tanh$ 函数决定最后输出的信息</p>
<ul>
<li>输出$o_t&#x3D;\sigma(W_oh_{t-1}+U_ox_t+b_o) , h_t&#x3D;o_t\odot tanhC_t$</li>
</ul>
</li>
<li><p>预测输出：$\hat{y}_t&#x3D;\sigma(Vh_t+c)$</p>
</li>
</ul>
<h4 id="LSTM解决RNN梯度消失问题"><a href="#LSTM解决RNN梯度消失问题" class="headerlink" title="LSTM解决RNN梯度消失问题"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhaojc1995/article/details/114649486">LSTM解决RNN梯度消失问题</a></h4><p> 1、cell state传播函数中的“加法”结构确实起了一定作用，它使得导数有可能大于1；<br>2、LSTM中逻辑门的参数可以一定程度控制不同时间步梯度消失的程度。</p>
<p>最后，LSTM依然不能完全解决梯度消失这个问题，有文献表示序列长度一般到了三百多仍然会出现梯度消失现象。如果想彻底规避这个问题，还是transformer好用</p>
<h2 id="6-Attention"><a href="#6-Attention" class="headerlink" title="6.Attention"></a>6.Attention</h2><h3 id="本质思想"><a href="#本质思想" class="headerlink" title="本质思想"></a>本质思想</h3><p>虽然 LSTM 解决了序列长距离依赖问题，但是单词超过 200 的时候就会失效。<strong>而 Attention 机制可以更加好的解决序列长距离依赖问题，并且具有并行计算能力</strong></p>
<p>首先我们得明确一个点，注意力模型从大量信息 Values 中筛选出少量重要信息，<strong>这些重要信息一定是相对于另外一个信息 Query 而言是重要的</strong>。也就是说，我们要搭建一个注意力模型，我们必须得要有一个 Query 和一个 Values，然后通过 Query 这个信息从 Values 中筛选出重要信息。简单点说，<strong>就是计算 Query 和 Values 中每个信息的相关程度。</strong></p>
<p><img src="https://img-blog.csdnimg.cn/direct/79464bde78ad46baabef1ab09061cbbc.png" alt="image-20240926141606010"></p>
<p>通过上图，Attention 通常可以进行如下描述，表示为将 Query(Q) 和 key-value pairs（<strong>把 Values 拆分成了键值对的形式</strong>） 映射到输出上，其中 query、每个 key、每个 value 都是向量，输出是 V 中所有 values 的加权，其中权重是由 Query 和每个 key 计算出来的，计算方法分为三步：</p>
<ul>
<li>第一步：计算比较 Q 和 K 的相似度，用 f 来表示：$f(Q,K_i)\quad i&#x3D;1,2,\cdots,m$,一般第一步计算方法包括四种<ul>
<li>点乘(<strong>Transformer使用</strong>):$f(Q,K_i)&#x3D;Q^TK_i$</li>
<li>权重：$f(Q,K_i)&#x3D;Q^TWK_i$</li>
<li>拼接权重：$: f(Q,K_i)&#x3D;W[Q^T;K_i]$</li>
<li>感知器：$f(Q,K_i)&#x3D;V^T\tanh(WQ+UK_i)$</li>
</ul>
</li>
<li>第二步：将得到的相似度进行 softmax 操作，进行归一化：$$\alpha_{i}&#x3D;softmax(\frac{f(Q,K_{i})}{\sqrt{d}_{k}})$$<ul>
<li>为什么除以$\sqrt{d}_{k}$: 假设 Q , K 里的元素的均值为0，方差为 1，那么 $A^T&#x3D;Q^TK$中元素的均值为 0，方差为 d。当 d 变得很大时， A 中的元素的方差也会变得很大，如果 A 中的元素方差很大(分布的方差大，分布集中在绝对值大的区域)，<strong>在数量级较大时， softmax 将几乎全部的概率分布都分配给了最大值对应的标签</strong>，由于某一维度的数量级较大，进而会导致 softmax 未来求梯度时会消失。</li>
<li>总结一下就是 $softmax⁡(A)$ 的分布会和d有关。因此 AA中每一个元素乘上 $\frac{1}{\sqrt{d}_{k}}$ 后，<strong>方差又变为 1，</strong>并且 A 的数量级也将会变小。</li>
</ul>
</li>
<li>第三步：针对计算出来的权重 αi，对 V 中的所有 values 进行加权求和计算，得到 Attention 向量:$Attention&#x3D;\sum_{i&#x3D;1}^m\alpha_iV_i$</li>
</ul>
<h3 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h3><p><img src="https://img-blog.csdnimg.cn/direct/365497885a4f4919aaa45ed880a51b68.png" alt="image-20240926144716980"></p>
<p>首先可以看到 Self Attention 有三个输入 Q、K、V：<strong>对于 Self Attention，Q、K、V 来自句子 X 的 词向量 x 的线性转化，即对于词向量 x，给定三个可学习的矩阵参数 $W_Q,W_k,W_v$，x 分别右乘上述矩阵得到 Q、K、V</strong>。</p>
<p><strong>计算流程</strong></p>
<ul>
<li>第一步，Q、K、V 的获取<img src="https://img-blog.csdnimg.cn/direct/516cbfebb23d42c69ac4584dc1707987.png" alt="image-20240926144847487"></li>
</ul>
<p>上图操作：两个单词 Thinking 和 Machines。通过线性变换，即$x_1 和 x_2$两个向量分别与$W_Q,W_k,W_v$ 三个矩阵点乘得到 $q_1,q_2,k_1,k_2,v_1,v_2 共 6 个向量。矩阵 Q 则是向量$ $q_1,q_2$ 的拼接，K、V 同理。</p>
<ul>
<li>第二步，MatMul<img src="https://img-blog.csdnimg.cn/direct/bc227fa5da5b46709d2715dd405cd409.png" alt="image-20240926145106372"></li>
</ul>
<p>上图操作：向量 $q_1,k_1$做点乘得到得分 112， $q_1,k_2$ 做点乘得到得分96。注意：<strong>这里是通过 $q_1$这个信息找到 $x_1,x_2$ 中的重要信息。</strong></p>
<ul>
<li>第三步和第四步，Scale + Softmax</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/direct/e6e5f5b56c994593926e2b559325baa2.png" alt="image-20240926145325955"></p>
<p>对该得分进行规范，除以 $\sqrt{d_k}&#x3D;8$</p>
<ul>
<li>第五步，MatMul</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/direct/489f71f3ec2c40b8945d1ae89dbdd633.png" alt="image-20240926145542828"></p>
<p>用得分比例 [0.88，0.12] 乘以 $[v_1,v_2]$ 值得到一个加权后的值，将这些值加起来得到 $z_1$</p>
<p>上述所说就是 Self Attention 模型所做的事，仔细感受一下，用$q_1$、$K&#x3D;[k_1,k_2]$去计算一个 Thinking 相对于 Thinking 和 Machine 的权重，再用权重乘以 Thinking 和 Machine 的$V&#x3D;[v_1,v_2]$ 得到加权后的 Thinking 和 Machine 的$V&#x3D;[v_1,v_2]$,最后求和得到针对各单词的输出$z_{1}$<br>同理可以计算出 Machine 相对于 Thinking 和 Machine 的加权输出$z_2$,拼接$z_1$和$z_2$即可得到 Attention 值$Z&#x3D;[z_1,z_2]$,这就是 Self<br>Attention 的矩阵计算，如下所示。<br>之前的例子是单个向量的运算例子。这张图展示的是矩阵运算的例子，输入是一个[2x4]的矩阵(句子中每个单词的词向量的拼接),每<br>个运算是[4x3]的矩阵，求得Q、K、V。</p>
<p><img src="https://img-blog.csdnimg.cn/direct/eee5f81a1cde499494b5c588a5820ba7.png" alt="image-20240926145931157"></p>
<p>Q对K转制做点乘，除以$\sqrt{d}_k$,做一个 softmax 得到合为 1 的比例，对V做点乘得到输出 Z。那么这个 Z 就是一个考虑过Thinking 周围单词Machine 的输出。</p>
<p><img src="https://img-blog.csdnimg.cn/direct/f4fffeb6e49a49ccadae84154f05c3d3.png" alt="image-20240926150145483"></p>
<p><strong>Self Attention 和 RNN、LSTM 的区别</strong></p>
<ul>
<li>RNN、LSTM：如果是 RNN 或者 LSTM，需要依次序列计算，对于远距离的相互依赖的特征，<strong>要经过若干时间步步骤的信息累积才能将两者联系起来，而距离越远，有效捕获的可能性越小</strong>。</li>
<li>Self Attention：<ul>
<li>引入 Self Attention 后会更容易捕获句子中长距离的相互依赖的特征，<strong>因为 Self Attention 在计算过程中会直接将句子中任意两个单词的联系通过一个计算步骤直接联系起来，所以远距离依赖特征之间的距离被极大缩短，有利于有效地利用这些特征</strong>；</li>
<li>除此之外，Self Attention 对于<strong>一句话中的每个单词都可以单独的进行 Attention 值的计算</strong>，也就是说 Self Attention 对计算的并行性也有直接帮助作用，而对于必须得依次序列计算的 RNN 而言，是无法做到并行计算的。</li>
</ul>
</li>
</ul>
<h4 id="Masked-Self-Attention-模型"><a href="#Masked-Self-Attention-模型" class="headerlink" title="Masked Self Attention 模型"></a>Masked Self Attention 模型</h4><p><img src="https://img-blog.csdnimg.cn/direct/7b91122adc5e465aaee55afc24a9b737.png" alt="image-20240926150727812"></p>
<p>我们已经通过 scale 之前的步骤得到了一个 attention map，<strong>而 mask 就是沿着对角线把灰色的区域用0覆盖掉，不给模型看到未来的信息</strong>，如下图所示<img src="https://img-blog.csdnimg.cn/direct/9fb4f7d68ec24fc4ba50ed23044bc593.png" alt="image-20240926150747585"></p>
<p>在做完 softmax 之后，横轴结果合为 1</p>
<h4 id="Multi-head-Self-Attention-模型"><a href="#Multi-head-Self-Attention-模型" class="headerlink" title="Multi-head Self Attention 模型"></a>Multi-head Self Attention 模型</h4><p>$\text{Multi-Head Attention 就是把 Self Attention 得到的注意力值}Z\text{切分成}\text{n个}Z_1,Z_2,\cdots,Z_n\\text{,然后通过全连接层获得新的 }Z^{\prime}$</p>
<img src="https://img-blog.csdnimg.cn/direct/3eda42531c8c48f995195263c07c4655.png" alt="image-20240926151121502" style="zoom:50%;" />

<p>我们对 $Z$ 进行 8 等份的切分得到 8 个 $Z_i$ 矩阵</p>
<img src="https://img-blog.csdnimg.cn/direct/7123375216ab466183021b21fbf8b98e.png" alt="image-20240926151206524" style="zoom:67%;" />

<p>为了使得输出与输入结构相同，拼接矩阵  $Z_i$  后乘以一个线性  $W_o$ 得到最终的 $Z$ </p>
<img src="https://img-blog.csdnimg.cn/direct/f7d3b1813e1746709aff99ca2b79cc94.png" alt="image-20240926151303986" style="zoom:50%;" />



<p>整个流程：<img src="https://img-blog.csdnimg.cn/direct/088bb4ea3ee14572871cff4b21a1ea17.png" alt="image-20240926151344964" style="zoom:67%;" /></p>
<p><strong>多头相当于把原始信息 Source 放入了多个子空间中，也就是捕捉了多个信息，对于使用 multi-head（多头） attention 的简单回答就是，多头保证了 attention 可以注意到不同子空间的信息，捕捉到更加丰富的特征信息</strong></p>
<h2 id="7-zero-shot-few-shot-Learning"><a href="#7-zero-shot-few-shot-Learning" class="headerlink" title="7.zero-shot few-shot Learning"></a>7.zero-shot few-shot Learning</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zcyzcyjava/article/details/127006287">概括</a></p>
<p><a target="_blank" rel="noopener" href="https://www.ibm.com/cn-zh/topics/zero-shot-learning">zero-shot learning</a></p>
<p><a target="_blank" rel="noopener" href="https://www.ibm.com/cn-zh/topics/few-shot-learning">few-shot learning</a></p>
<h2 id="8-N-gram"><a href="#8-N-gram" class="headerlink" title="8.N-gram"></a>8.N-gram</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/songbinxu/article/details/80209197">一文读懂</a></p>
<h2 id="9-分词"><a href="#9-分词" class="headerlink" title="9.分词"></a>9.分词</h2><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7088322473640329230">一文读懂</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/nickchen121/p/16470569.html#tid-EEyxQf">click here</a></p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">jingxiaoyang</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://yangjx29.github.io/posts/96138251.html">https://yangjx29.github.io/posts/96138251.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">jingxiaoyang</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'Ov23liIM5S2VDoNlIHcI',
        clientSecret: 'd317e52266d8a27cc292d6bd87d8579175675baa',
        repo: 'gitalk',
        owner: 'yangjx29',
        admin: "yangjx29",
        id: '2024-09-25T16-58-41',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/1bb262dc.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/21.jpg" class="responsive-img" alt="bert">
                        
                        <span class="card-title">bert</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-09-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/paper-reading/" class="post-category">
                                    paper reading
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/674e3c36.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/7.jpg" class="responsive-img" alt="transfomer">
                        
                        <span class="card-title">transfomer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-09-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/paper-reading/" class="post-category">
                                    paper reading
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

            

                <div class="container row center-align"
                    style="margin-bottom: 15px !important;">
                    <div class="col s12 m8 l8 copy-right">
                        Copyright&nbsp;&copy;
                        
                            <span id="year">2023-2024</span>
                            
                                    <a href="/about" target="_blank">jingxiaoyang</a>
                                    |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
                                    |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery"
                                        target="_blank">Matery</a>
                                    
                                            <br>
                                            
                                                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">
                                                        243.2k
                                                    </span>
                                                    
                                                        
                                                            
                                                                
                                                                    
                                                                        
                                                                            <span id="busuanzi_container_site_pv">
                                                                                &nbsp;|&nbsp;<i
                                                                                    class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                                                                                    <span id="busuanzi_value_site_pv"
                                                                                        class="white-color"></span>
                                                                            </span>
                                                                            
                                                                                
                                                                                    <span
                                                                                        id="busuanzi_container_site_uv">
                                                                                        &nbsp;|&nbsp;<i
                                                                                            class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                                                                                            <span
                                                                                                id="busuanzi_value_site_uv"
                                                                                                class="white-color"></span>
                                                                                    </span>
                                                                                    
                                                                                        <br>

                                                                                        <!-- 运行天数提醒. -->
                                                                                        
                                                                                            <span id="sitetime"> Loading
                                                                                                ...</span>
                                                                                            <script>
                                                                                                var calcSiteTime = function () {
                                                                                                    var seconds = 1000;
                                                                                                    var minutes = seconds * 60;
                                                                                                    var hours = minutes * 60;
                                                                                                    var days = hours * 24;
                                                                                                    var years = days * 365;
                                                                                                    var today = new Date();
                                                                                                    var startYear = "2023";
                                                                                                    var startMonth = "4";
                                                                                                    var startDate = "29";
                                                                                                    var startHour = "0";
                                                                                                    var startMinute = "0";
                                                                                                    var startSecond = "0";
                                                                                                    var todayYear = today.getFullYear();
                                                                                                    var todayMonth = today.getMonth() + 1;
                                                                                                    var todayDate = today.getDate();
                                                                                                    var todayHour = today.getHours();
                                                                                                    var todayMinute = today.getMinutes();
                                                                                                    var todaySecond = today.getSeconds();
                                                                                                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                                                                                                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                                                                                                    var diff = t2 - t1;
                                                                                                    var diffYears = Math.floor(diff / years);
                                                                                                    var diffDays = Math.floor((diff / days) - diffYears * 365);

                                                                                                    // 区分是否有年份.
                                                                                                    var language = 'zh-CN';
                                                                                                    if (startYear === String(todayYear)) {
                                                                                                        document.getElementById("year").innerHTML = todayYear;
                                                                                                        var daysTip = 'This site has been running for ' + diffDays + ' days';
                                                                                                        if (language === 'zh-CN') {
                                                                                                            daysTip = '已经在一起 ' + diffDays + ' 天';
                                                                                                        } else if (language === 'zh-HK') {
                                                                                                            daysTip = '本站已運行 ' + diffDays + ' 天';
                                                                                                        }
                                                                                                        document.getElementById("sitetime").innerHTML = daysTip;
                                                                                                    } else {
                                                                                                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                                                                                                        var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                                                                                            + diffDays + ' days';
                                                                                                        if (language === 'zh-CN') {
                                                                                                            yearsAndDaysTip = '已经在一起 ' + diffYears + ' 年 ' + diffDays + ' 天';
                                                                                                        } else if (language === 'zh-HK') {
                                                                                                            yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                                                                                                        }
                                                                                                        document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                                                                                                    }
                                                                                                }

                                                                                                calcSiteTime();
                                                                                            </script>
                                                                                            
                                                                                                <br>
                                                                                                
                    </div>
                    <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/yangjx29" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:2372256530@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2372256530" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2372256530" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>








                    </div>
                </div>
</footer>

<div class="progress-bar"></div>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/snow.js"><\/script>');
            }
        </script>
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    
    <script>
        (function (i, s, o, g, r, a, m) {
            i["DaoVoiceObject"] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o), m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            a.charset = "utf-8";
            m.parentNode.insertBefore(a, m)
        })(window, document, "script", ('https:' == document.location.protocol ? 'https:' : 'http:') +
            "//widget.daovoice.io/widget/6984b559.js", "daovoice")
        daovoice('init', {
            app_id: ""
        });
        daovoice('update');
    </script>
    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
