<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="peft学习笔记, JacksonYang的博客">
    <meta name="description" content="

peft学习笔记第一次使用lora微调，踩的坑已经多到心力憔悴。所以写一篇博客，总结梳理一下我混乱的逻辑。
什么是loraLoRA 的全称是 LoRA: Low-Rank Adaptation of Large Language Mod">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>peft学习笔记 | JacksonYang的博客</title>
    <link rel="icon" type="image/png" href="/medias/image.png">
    
    <style>
        body{
            background-image: url(/medias/banner/11.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/image.svg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JacksonYang的博客</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/MyArxiv" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>定制Arxiv</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/image.svg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JacksonYang的博客</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/MyArxiv" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			定制Arxiv
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">peft学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/ML/" class="post-category">
                                ML
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-12-02
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    3.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    13 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <meta name="referrer" content="no-referrer"/>

<h1 id="peft学习笔记"><a href="#peft学习笔记" class="headerlink" title="peft学习笔记"></a>peft学习笔记</h1><p>第一次使用lora微调，踩的坑已经多到心力憔悴。所以写一篇博客，总结梳理一下我混乱的逻辑。</p>
<h2 id="什么是lora"><a href="#什么是lora" class="headerlink" title="什么是lora"></a>什么是lora</h2><p>LoRA 的全称是 <strong>LoRA: Low-Rank Adaptation of Large Language Models</strong>，是一种以极低资源<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E5%BE%AE%E8%B0%83&spm=1001.2101.3001.7020">微调</a><a target="_blank" rel="noopener" href="https://edu.csdn.net/cloud/pm_summit?utm_source=blogglc&spm=1001.2101.3001.7020">大模型</a>的方法，其来自于论文 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.09685">LoRA: Low-Rank Adaptation of Large Language Models</a> (还没读~)</p>
<p>Lora是PEFT微调方式的一种，google在论文<a href="https://link.zhihu.com/?target=https://arxiv.org/pdf/1902.00751.pdf">《Parameter-Efficient Transfer Learning for NLP》</a>指出，在面对特定的下游任务时，如果进行 Full-Fintuning（即预训练模型中的所有参数都进行微调），太过低效；而如果采用固定预训练模型的某些层，只微调接近下游任务的那几层参数，又难以达到较好的效果。</p>
<p>在 LoRA 方法提出之前，也有很多方法尝试解决大模型微调困境的问题。其中有两个主要的方向：</p>
<ul>
<li>添加 adapter 层；</li>
<li>使用 prefix-tuning。</li>
</ul>
<p>但是这两种方法都有局限性：</p>
<ul>
<li>Adapter 层会引入推理时延。简单来说，它的主要思想是在预训练模型的每一层 Transformer 中插入一个小的可训练的模块，称为 adapter。这样可以保持预训练模型的权重不变，只更新 adapter 的参数，从而实现参数高效和灵活的迁移学习。</li>
<li>Prefix-tuning 难以优化。prefix-tuning 方法是受语言模型 in-context learning 能力的启发，只要有合适的上下文则语言模型可以很好地解决自然语言任务。但是，针对特定的任务找到离散 token 的前缀需要花费很长时间，prefix-tuning 提出使用连续的 virtual token embedding 来替换离散 token。这些 virtual token embedding 需要作为可训练参数进行优化，而且会减少下游任务的序列长度</li>
</ul>
<p>LoRA 的核心思想是冻结<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E9%A2%84%E8%AE%AD%E7%BB%83&spm=1001.2101.3001.7020">预训练</a>的模型权重，并将可训练的秩分解矩阵注入 Transformer 架构的每一层，从而大大减少了下游任务的可训练参数数量。相比于完全微调，LoRA 可以节省显存、提高训练速度、减少推理延迟，并且保持或提升模型质量</p>
<p>lora可以应用于自回归模型 如 GPT 系列和 Encoder-Decoder 模型（如 T5），并且可以与不同规模的预训练模型（如 RoBERTa, DeBERTa, GPT-2, GPT-3）兼容。</p>
<h2 id="LoRA使用"><a href="#LoRA使用" class="headerlink" title="LoRA使用"></a>LoRA使用</h2><p>在使用前，首先需要配置环境，用到peft库，源码在<a target="_blank" rel="noopener" href="https://github.com/huggingface/peft">https://github.com/huggingface/peft</a></p>
<p>然后可以开始使用。</p>
<p><strong>前期准备</strong></p>
<ul>
<li>加载预训练模型+数据集准备<ul>
<li>这里使用huggingface api即可，示例Model选择codeT5</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">MODEL_CLASSES = &#123;</span><br><span class="line">    <span class="string">&#x27;gpt2&#x27;</span>: (GPT2Config, GPT2LMHeadModel, GPT2Tokenizer),</span><br><span class="line">    <span class="string">&#x27;openai-gpt&#x27;</span>: (OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer),</span><br><span class="line">    <span class="string">&#x27;bert&#x27;</span>: (BertConfig, BertForMaskedLM, BertTokenizer),</span><br><span class="line">    <span class="string">&#x27;roberta&#x27;</span>: (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer),</span><br><span class="line">    <span class="string">&#x27;distilbert&#x27;</span>: (DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer),</span><br><span class="line">    <span class="string">&#x27;codet5&#x27;</span>: (T5Config, T5ForConditionalGeneration, RobertaTokenizer)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, get_peft_model,PeftModel, TaskType,PeftConfig</span><br><span class="line"></span><br><span class="line">config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]</span><br><span class="line"></span><br><span class="line">config = config_class.from_pretrained(args.config_name <span class="keyword">if</span> args.config_name <span class="keyword">else</span> args.model_name_or_path,</span><br><span class="line">                                          cache_dir=args.cache_dir <span class="keyword">if</span> args.cache_dir <span class="keyword">else</span> <span class="literal">None</span>)</span><br><span class="line">config.num_labels=<span class="number">1</span></span><br><span class="line">tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name,</span><br><span class="line">                                                do_lower_case=args.do_lower_case,</span><br><span class="line">                                                cache_dir=args.cache_dir <span class="keyword">if</span> args.cache_dir <span class="keyword">else</span> <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<ol>
<li><strong>定义用到的类和方法</strong></li>
</ol>
<p><strong>LoraConfig</strong></p>
<p>LoraConfig是 <code>peft</code> 库中配置 LoRA 层的核心工具，用于配置低秩适应（LoRA）相关的参数，以便在训练过程中调整模型的部分参数。允许你自定义如何在模型中应用 LoRA 技术。</p>
<p><strong><code>r</code> (低秩矩阵的秩)</strong></p>
<ul>
<li><strong>作用</strong>：这是 LoRA 层的核心参数之一，它控制低秩矩阵的秩（rank）。在 LoRA 方法中，我们将权重矩阵分解为低秩矩阵，通过调整秩的大小来控制训练中需要更新的参数数量</li>
</ul>
<p><strong><code>lora_alpha</code> (LoRA的缩放因子)</strong></p>
<ul>
<li><strong>作用</strong>：<code>lora_alpha</code> 是 LoRA 的缩放因子，用来调整低秩矩阵对模型输出的影响程度。LoRA 会将原始权重矩阵与低秩矩阵相加，而 <code>lora_alpha</code> 用于缩放低秩矩阵的贡献</li>
</ul>
<p><strong><code>target_modules</code> (应用 LoRA 的模块)</strong></p>
<ul>
<li><strong>作用</strong>：LoRA 只会应用于某些特定的模块，通常是在模型的某些层中，例如全连接层或自注意力层。<code>target_modules</code> 允许你指定哪些模块应用 LoRA。</li>
</ul>
<p><strong><code>lora_dropout</code> (Dropout 比率)</strong></p>
<ul>
<li><strong>作用</strong>：这是 LoRA 层的 dropout 参数，用于控制在低秩矩阵中的 dropout 率。dropout 是一种正则化技术，能有效防止过拟合。在 LoRA 中，dropout 会随机丢弃低秩矩阵中的部分元素</li>
</ul>
<p><strong><code>bias</code> (对偏置项的处理方式)</strong></p>
<ul>
<li><strong>作用</strong>：LoRA 层允许你选择是否对偏置项进行处理。偏置项是模型中的常数项，通常不会像权重矩阵那样进行学习。</li>
</ul>
<p><code>task_type</code> ()</p>
<ul>
<li><p>选择期望的下游任务类型</p>
<blockquote>
<p>Overview of the supported task types:</p>
<ul>
<li>SEQ_CLS: Text classification.</li>
<li>SEQ_2_SEQ_LM: Sequence-to-sequence language modeling.</li>
<li>CAUSAL_LM: Causal language modeling.</li>
<li>TOKEN_CLS: Token classification.</li>
<li>QUESTION_ANS: Question answering.</li>
<li>FEATURE_EXTRACTION: Feature extraction. Provides the hidden states which can be used as embeddings or features<br>for downstream tasks.</li>
</ul>
</blockquote>
</li>
</ul>
<p>其他参数：参考源代码&#x2F;peft&#x2F;tuners&#x2F;lora&#x2F;config.py</p>
<p>eg:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">lora_config = LoraConfig(</span><br><span class="line">        task_type=TaskType.TOKEN_CLS,</span><br><span class="line">        r=<span class="number">8</span>,  <span class="comment"># 低秩矩阵的秩，通常选择 4-16 之间</span></span><br><span class="line">        lora_alpha=<span class="number">16</span>,  <span class="comment"># LoRA 系数</span></span><br><span class="line">        lora_dropout=<span class="number">0.1</span>,  <span class="comment"># dropout 比例</span></span><br><span class="line">        target_modules=[</span><br><span class="line">        <span class="string">&quot;q&quot;</span>,  <span class="comment"># SelfAttention 中的查询</span></span><br><span class="line">        <span class="string">&quot;k&quot;</span>,  <span class="comment"># SelfAttention 中的键</span></span><br><span class="line">        <span class="string">&quot;v&quot;</span>,  <span class="comment"># SelfAttention 中的值</span></span><br><span class="line">        <span class="string">&quot;o&quot;</span>,  <span class="comment"># SelfAttention 中的输出</span></span><br><span class="line">        ],  <span class="comment"># 目标模块（这里是自注意力层的 query、key 和 value）</span></span><br><span class="line">        bias=<span class="string">&quot;none&quot;</span>,  <span class="comment"># 是否调整偏置项</span></span><br><span class="line">        inference_mode=<span class="literal">False</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<p><strong>get_peft_model()</strong></p>
<ul>
<li><code>get_peft_model</code> 是 <code>peft</code> 库中的一个函数，它的主要作用是 <strong>将一个已有的预训练模型转换为带有高效微调模块（如 LoRA）的模型</strong>，从而可以在不改变原始模型大部分参数的情况下，通过少量的可训练参数进行高效的微调</li>
</ul>
<p>eg：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = get_peft_model(model, lora_config)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>训练</strong></li>
</ol>
<p><strong>TrainingArguments</strong></p>
<ul>
<li><p>通过设置 <code>TrainingArguments</code>，我们可以轻松地定义训练时的各种参数，例如学习率、批量大小、训练轮次、日志记录频率等。这个类是 <code>Trainer</code> 类的一个重要输入</p>
</li>
<li><p>参数包括 </p>
<ul>
<li><p><strong><code>output_dir</code></strong>: 指定训练结果（模型、检查点、日志等）保存的目录。</p>
<p><strong><code>evaluation_strategy</code></strong>: 定义何时进行评估，可以设置为 <code>no</code>, <code>epoch</code> 或 <code>steps</code>。如果设置为 <code>epoch</code>，则在每个训练周期结束时进行评估；如果是 <code>steps</code>，则在每个 <code>save_steps</code> 设置的步数后进行评估。</p>
<p><strong><code>save_steps</code></strong>: 定义每多少步保存一次模型检查点。</p>
<p><strong><code>save_total_limit</code></strong>: 如果指定了该值，则会保存最多指定数量的检查点，并删除最旧的检查点。</p>
<p><strong><code>logging_dir</code></strong>: 日志文件的保存路径。日志通常用于记录训练过程中的详细信息，如损失值、学习率等。</p>
<p><strong><code>logging_steps</code></strong>: 设置每隔多少步记录一次日志。</p>
<p><strong><code>learning_rate</code></strong>: 设置学习率。</p>
<p><strong><code>per_device_train_batch_size</code></strong>: 每个设备上的训练批次大小（例如，GPU或TPU）。</p>
<p><strong><code>per_device_eval_batch_size</code></strong>: 每个设备上的评估批次大小。</p>
<p><strong><code>num_train_epochs</code></strong>: 设置训练的总轮次。</p>
<p><strong><code>weight_decay</code></strong>: 权重衰减系数，通常用于防止过拟合。</p>
<p><strong><code>adam_epsilon</code></strong>: Adam 优化器的 epsilon 参数。</p>
<p><strong><code>logging_first_step</code></strong>: 如果为 <code>True</code>，则在训练的第一步就记录日志。</p>
<p><strong><code>load_best_model_at_end</code></strong>: 如果设置为 <code>True</code>，则在训练结束后加载验证集上表现最好的模型。</p>
<p><strong><code>metric_for_best_model</code></strong>: 指定用于选择最好的模型的评估指标（例如 <code>accuracy</code>, <code>loss</code> 等）。</p>
</li>
</ul>
</li>
</ul>
<p><strong>Trainer</strong></p>
<p><code>Trainer</code> 是 <code>transformers</code> 库提供的一个高层接口，用于简化模型训练过程。<code>Trainer</code> 处理了训练、评估、预测等任务，并与 <code>TrainingArguments</code> 配合使用，自动进行模型训练、验证、保存和日志记录等操作。</p>
<p><strong>主要功能</strong></p>
<ul>
<li><strong>训练</strong>：自动管理训练过程，包括前向传播、反向传播、损失计算和优化。</li>
<li><strong>评估</strong>：在训练过程中按设定的策略（如每隔一定步数或每个周期结束时）评估模型。</li>
<li><strong>日志记录</strong>：在训练过程中，<code>Trainer</code> 会自动记录训练日志，例如损失、学习率、时间等。</li>
<li><strong>保存模型</strong>：在训练过程中自动保存模型检查点。</li>
<li><strong>加载最佳模型</strong>：如果启用了 <code>load_best_model_at_end</code>，则 <code>Trainer</code> 会在训练结束后加载表现最好的模型。</li>
</ul>
<p><strong>主要参数</strong></p>
<ul>
<li><strong><code>model</code></strong>: 要训练的模型（例如，BertForSequenceClassification）。</li>
<li><strong><code>args</code></strong>: <code>TrainingArguments</code> 对象，定义了训练过程的配置。</li>
<li><strong><code>train_dataset</code></strong>: 训练数据集。</li>
<li><strong><code>eval_dataset</code></strong>: 验证数据集。</li>
<li><strong><code>compute_metrics</code></strong>: 一个函数，用于计算评估指标（例如准确率、F1分数）。</li>
<li><strong><code>tokenizer</code></strong>: 用于对文本数据进行处理和编码的分词器。</li>
<li><strong><code>callbacks</code></strong>: 可选的回调函数，可以在训练过程中添加自定义操作。</li>
<li><strong><code>data_collator</code></strong>: 用于打包输入数据的函数，通常用于处理批量数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args, train_dataset, eval_dataset,model, tokenizer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Train the model </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span> </span><br><span class="line">    <span class="comment"># 定义训练参数</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    args.output_dir: 用来保存训练过程中的一些中间文件，如模型检查点、日志文件等。具体保存内容包括：</span></span><br><span class="line"><span class="string">    checkpoint-* 文件夹：这些文件夹包含了每个检查点（checkpoint）的模型权重和配置文件。</span></span><br><span class="line"><span class="string">    trainer_state.json：记录训练过程中的状态信息（如训练的步数、学习率等）。</span></span><br><span class="line"><span class="string">    eval_results 等：保存评估过程中的结果（例如损失值等</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    training_args = TrainingArguments(</span><br><span class="line">        output_dir= args.output_dir,  <span class="comment"># 保存训练结果的目录</span></span><br><span class="line">        eval_strategy=<span class="string">&quot;steps&quot;</span>,  <span class="comment"># 每个 steps 评估一次,同保存策略一致</span></span><br><span class="line">        num_train_epochs=<span class="number">3</span>,  <span class="comment"># 训练轮次</span></span><br><span class="line">        per_device_train_batch_size=<span class="number">8</span>,  <span class="comment"># 每个设备上的批量大小</span></span><br><span class="line">        per_device_eval_batch_size=<span class="number">32</span>,  <span class="comment"># 每个设备上的评估批量大小</span></span><br><span class="line">        logging_dir=<span class="string">&quot;./logs&quot;</span>,  <span class="comment"># 日志目录</span></span><br><span class="line">        logging_steps=<span class="number">1000</span>,  <span class="comment"># 每1000步记录一次日志</span></span><br><span class="line">        save_steps=<span class="number">1000</span>,  <span class="comment"># 每1000步保存一次模型</span></span><br><span class="line">        <span class="comment"># load_best_model_at_end=True,  # 加载最佳模型</span></span><br><span class="line">        <span class="comment"># metric_for_best_model=&quot;accuracy&quot;,  # 你可以选择自己想要的评估标准（例如准确率）</span></span><br><span class="line">        <span class="comment"># lr_scheduler_type=&#x27;linear&#x27;,  # 使用线性衰减的学习率调度</span></span><br><span class="line">        learning_rate=<span class="number">5e-5</span>,  <span class="comment"># 调整学习率</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义 Trainer 类进行训练</span></span><br><span class="line">    trainer = Trainer(</span><br><span class="line">        model=model,  <span class="comment"># 需要微调的模型</span></span><br><span class="line">        args=training_args,  <span class="comment"># 训练参数</span></span><br><span class="line">        tokenizer=tokenizer,  <span class="comment"># 分词器</span></span><br><span class="line">        train_dataset=train_dataset,  <span class="comment"># 训练数据集</span></span><br><span class="line">        eval_dataset= eval_dataset,  <span class="comment"># 验证数据集</span></span><br><span class="line">        <span class="comment"># compute_metrics= compute_metrics,</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始训练</span></span><br><span class="line">    trainer.train()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存微调后的模型</span></span><br><span class="line">    trainer.save_model(<span class="string">&quot;./finetuned_codet5_lora&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Model saved&quot;</span>)</span><br><span class="line">    model.save_pretrained(<span class="string">&quot;./saved_models/acc_model&quot;</span>) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 评估模型</span></span><br><span class="line">    eval_results = trainer.evaluate()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;eval_results: <span class="subst">&#123;eval_results&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>trainer.save_model和model.save_pretrained区别：</strong></p>
<table>
<thead>
<tr>
<th>功能</th>
<th>trainer.save_model</th>
<th>model.save_pretrained</th>
</tr>
</thead>
<tbody><tr>
<td>保存内容</td>
<td>保存模型的权重、配置文件、训练状态（优化器、学习率等</td>
<td>仅保存模型的权重和配置文件（不包括训练状态）。</td>
</tr>
<tr>
<td>适用场景</td>
<td>适用于使用 <code>Trainer</code> 训练时，保存训练后的完整模型</td>
<td>适用于只需要保存模型的权重和配置文件，通常用于微调后的模型</td>
</tr>
<tr>
<td>是否包括训练状态</td>
<td>包括训练状态（如优化器、学习率调度器等）</td>
<td>不包括训练状态，只保存模型本身</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>如果你使用 <code>Trainer</code> 进行训练并且希望保存训练过程中的所有信息（如训练状态、模型参数等），推荐使用 <code>trainer.save_model</code>。</p>
<p>如果你仅关心保存训练后的模型（例如，在微调后进行推理或部署），可以使用 <code>model.save_pretrained</code></p>
<ol start="3">
<li>推理</li>
</ol>
<p>我用分类任务做示例。</p>
<p>推理的基本过程包括以下几个步骤：</p>
<ol>
<li><strong>加载模型和分词器</strong>：加载训练后保存的模型（或预训练模型）和对应的分词器（tokenizer）。</li>
</ol>
<p>这个过程没有什么差别，同样使用from_pretrain加载微调后的模型。如果在训练时修改了分词器（例如，添加了新的词汇），也应该加载分词器</p>
<ol start="2">
<li><p><strong>准备输入数据</strong>：根据需要对输入数据进行预处理和编码，使其适合输入到模型中。</p>
</li>
<li><p><strong>进行推理</strong>：将预处理后的数据输入模型进行推理，获取模型的输出</p>
</li>
</ol>
<h2 id="LoRA-的原理和实现"><a href="#LoRA-的原理和实现" class="headerlink" title="LoRA 的原理和实现"></a>LoRA 的原理和实现</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Sbtgmz/article/details/131175878">https://blog.csdn.net/Sbtgmz/article/details/131175878</a></p>
<p>LoRA 为了更加参数高效，使用相对非常小的参数$\Theta$来表示任务相关的参数增量$\Delta\Phi&#x3D;\Delta\Phi(\Theta)$ ,其中$|\Theta|\ll|\Phi_0|$。寻找$\Delta\Phi$的任务就变成对$\Theta$的优化：</p>
<p>$$\max_\Theta\sum_{(x,y)\in\mathcal{Z}}\sum_{t&#x3D;1}^{|y|}\log(p_{\Phi_0+\Delta\Phi(\Theta)}\left(y_t\left|x,y_{&lt;t}\right.\right))$$ </p>
<p>LoRA 将会使用低秩表示来编码$\Delta\Phi$ ,同时实现计算高效和存储高效。当预训练模型是 175B GPT-3, 可训练参数$|\Theta|$可以小至$|\Phi_0|$的$0.01%$。对于预训练权重矩阵$W_0\in\mathbb{R}^{d\times k}$,可以通过低秩分解来表示其更新$W_0+\Delta W&#x3D;W_0+BA,B\in\mathbb{R}^{d\times r},A\in\mathbb{R}^{r\times k}$ 且秩 $r\ll$ $\min(d,k)$ 。在训练过程中<strong>，$W_0$被冻结且不接受梯度更新，$A$和$B$则是可训练参数</strong>。注意，$W_{0}$和$\Delta W&#x3D;BA$都会乘以相同的输入。对于$h&#x3D;W_{0}x$ ,前向传播变为：</p>
<p>$$h&#x3D;W_0x+\Delta Wx&#x3D;W_0x+BAx$$</p>
<p>对矩阵$A$使用随机高斯初始化，对矩阵$B$使用 0 进行初始化，因此$\Delta W&#x3D;BA$在训练的开始为 0。使用$\frac\alpha r$来缩放$\Delta Wx$ 。当使用Adam 优化时，经过适当的缩放初始化，调优$\alpha$与调优学习率大致相同。当进行部署时，以显式的计算和存储$W&#x3D;W_0+BA$,并正常执行推理。$W_{0}$和$BA$都是$\mathbb{R}^{d\times k}$ 。当需要转换至另一个下游任务，可以通过减去$BA$来恢复$W_0$ ,然后添加不同的$B^{\prime}A^{\prime}$ 。</p>
<p>LoRA 模型作为一种以极低资源微调大模型的方法，可以应用于以下一些场景：</p>
<ul>
<li>需要使用大规模预训练语言模型来解决特定的自然语言处理任务，例如机器阅读理解、文本摘要、文本分类等，但是又受限于硬件资源或者成本预算的场景。</li>
<li>需要根据不同的用户或者领域来定制化大规模预训练语言模型的生成风格或者内容，例如对话系统、文本生成、文本风格转换等，但是又不想为每个用户或者领域保存一份完整微调的模型的场景。</li>
<li>需要在不同的下游任务之间快速切换大规模预训练语言模型的能力，例如多任务学习、元学习、迁移学习等，但是又不想重新训练或者加载完整微调的模型的场景。</li>
</ul>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">jingxiaoyang</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://yangjx29.github.io/posts/110ad625.html">https://yangjx29.github.io/posts/110ad625.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">jingxiaoyang</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'Ov23liIM5S2VDoNlIHcI',
        clientSecret: 'd317e52266d8a27cc292d6bd87d8579175675baa',
        repo: 'gitalk',
        owner: 'yangjx29',
        admin: "yangjx29",
        id: '2024-12-02T11-36-12',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/102fa210.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/5.jpg" class="responsive-img" alt="Pytorch-Sampler类学习笔记">
                        
                        <span class="card-title">Pytorch-Sampler类学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/ML/" class="post-category">
                                    ML
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/92012s0215.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="Large Language Model for Vulnerability Detection Emerging Results and Future Directions">
                        
                        <span class="card-title">Large Language Model for Vulnerability Detection Emerging Results and Future Directions</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/paper-reading/" class="post-category">
                                    paper reading
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

            

                <div class="container row center-align"
                    style="margin-bottom: 15px !important;">
                    <div class="col s12 m8 l8 copy-right">
                        Copyright&nbsp;&copy;
                        
                            <span id="year">2023-2024</span>
                            
                                    <a href="/about" target="_blank">jingxiaoyang</a>
                                    |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
                                    |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery"
                                        target="_blank">Matery</a>
                                    
                                            <br>
                                            
                                                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">
                                                        276.8k
                                                    </span>
                                                    
                                                        
                                                            
                                                                
                                                                    
                                                                        
                                                                            <span id="busuanzi_container_site_pv">
                                                                                &nbsp;|&nbsp;<i
                                                                                    class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                                                                                    <span id="busuanzi_value_site_pv"
                                                                                        class="white-color"></span>
                                                                            </span>
                                                                            
                                                                                
                                                                                    <span
                                                                                        id="busuanzi_container_site_uv">
                                                                                        &nbsp;|&nbsp;<i
                                                                                            class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                                                                                            <span
                                                                                                id="busuanzi_value_site_uv"
                                                                                                class="white-color"></span>
                                                                                    </span>
                                                                                    
                                                                                        <br>

                                                                                        <!-- 运行天数提醒. -->
                                                                                        
                                                                                            <span id="sitetime"> Loading
                                                                                                ...</span>
                                                                                            <script>
                                                                                                var calcSiteTime = function () {
                                                                                                    var seconds = 1000;
                                                                                                    var minutes = seconds * 60;
                                                                                                    var hours = minutes * 60;
                                                                                                    var days = hours * 24;
                                                                                                    var years = days * 365;
                                                                                                    var today = new Date();
                                                                                                    var startYear = "2023";
                                                                                                    var startMonth = "4";
                                                                                                    var startDate = "29";
                                                                                                    var startHour = "0";
                                                                                                    var startMinute = "0";
                                                                                                    var startSecond = "0";
                                                                                                    var todayYear = today.getFullYear();
                                                                                                    var todayMonth = today.getMonth() + 1;
                                                                                                    var todayDate = today.getDate();
                                                                                                    var todayHour = today.getHours();
                                                                                                    var todayMinute = today.getMinutes();
                                                                                                    var todaySecond = today.getSeconds();
                                                                                                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                                                                                                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                                                                                                    var diff = t2 - t1;
                                                                                                    var diffYears = Math.floor(diff / years);
                                                                                                    var diffDays = Math.floor((diff / days) - diffYears * 365);

                                                                                                    // 区分是否有年份.
                                                                                                    var language = 'zh-CN';
                                                                                                    if (startYear === String(todayYear)) {
                                                                                                        document.getElementById("year").innerHTML = todayYear;
                                                                                                        var daysTip = 'This site has been running for ' + diffDays + ' days';
                                                                                                        if (language === 'zh-CN') {
                                                                                                            daysTip = '已经在一起 ' + diffDays + ' 天';
                                                                                                        } else if (language === 'zh-HK') {
                                                                                                            daysTip = '本站已運行 ' + diffDays + ' 天';
                                                                                                        }
                                                                                                        document.getElementById("sitetime").innerHTML = daysTip;
                                                                                                    } else {
                                                                                                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                                                                                                        var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                                                                                            + diffDays + ' days';
                                                                                                        if (language === 'zh-CN') {
                                                                                                            yearsAndDaysTip = '已经在一起 ' + diffYears + ' 年 ' + diffDays + ' 天';
                                                                                                        } else if (language === 'zh-HK') {
                                                                                                            yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                                                                                                        }
                                                                                                        document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                                                                                                    }
                                                                                                }

                                                                                                calcSiteTime();
                                                                                            </script>
                                                                                            
                                                                                                <br>
                                                                                                
                    </div>
                    <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/yangjx29" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:2372256530@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2372256530" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2372256530" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>








                    </div>
                </div>
</footer>

<div class="progress-bar"></div>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/snow.js"><\/script>');
            }
        </script>
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    
    <script>
        (function (i, s, o, g, r, a, m) {
            i["DaoVoiceObject"] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o), m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            a.charset = "utf-8";
            m.parentNode.insertBefore(a, m)
        })(window, document, "script", ('https:' == document.location.protocol ? 'https:' : 'http:') +
            "//widget.daovoice.io/widget/6984b559.js", "daovoice")
        daovoice('init', {
            app_id: ""
        });
        daovoice('update');
    </script>
    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
